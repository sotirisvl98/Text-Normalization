{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad1e1642-c4c5-4428-980e-29a69bd5225e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6416eab0-df36-46d7-b3c0-8d9b09d52d22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import AzureOpenAI\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ad1e24e-3a01-4115-b9e7-34fa50a6c2a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_path = 'Dataset/normalization_assesment_dataset_10k.csv'\n",
    "df = pd.read_csv(df_path)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "565fad69-4ace-49d8-ae93-6db680989ac0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df['raw_comp_writers_text'] = df['raw_comp_writers_text'].str.strip()\n",
    "df.replace(\"\", pd.NA, inplace=True)\n",
    "df = df.dropna()\n",
    "print(df['raw_comp_writers_text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33d26316-9d51-4245-86dc-06a7cdef24c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_config(config_file):\n",
    "    with open(config_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "config = read_config('configuration.yaml')\n",
    "\n",
    "api_key = config['api_key']\n",
    "api_base =  config['api_base']\n",
    "api_version = config['api_version']\n",
    "model = config['model']\n",
    "\n",
    "client = AzureOpenAI(\n",
    "        api_key=api_key,\n",
    "        api_version=api_version,\n",
    "        base_url=f\"{api_base}/openai/deployments/{model}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c36de06c-531f-48f7-8165-872a770fed42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Normalize the following raw text by  removing redundant information, and keeping only the writer names in the output.\\n\n",
    "Raw Text: \"{raw_text}\"\n",
    "Normalized Text:\n",
    "\"\"\"\n",
    "\n",
    "def normalize_with_gpt(raw_text, few_shot_prompt):\n",
    "    prompt = few_shot_prompt.format(raw_text=raw_text)\n",
    "\n",
    "    # Call Azure OpenAI API\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # Replace with your Azure deployment name\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"\"\"You are a helpful assistant who aids with text normalization on music industry. The goal is to normalize given text, removing redundant information, and keeping only the writer names in the output. \\n \n",
    "            Here are some examples: \\n\\n\n",
    "\n",
    "            Example1:\n",
    "            RAW TEXT: <Unknown>/Wright, Justyce Kaseem\n",
    "            Normalized Text: Justyce Kaseem Wright\n",
    "            Example 2:\n",
    "            RAW TEXT: Pixouu/Abdou Gambetta/Copyright Control\n",
    "            Normalized Text: Pixouu/Abdou Gambetta\n",
    "            Example 3:\n",
    "            RAW TEXT: Mike Hoyer/JERRY CHESNUT/SONY/ATV MUSIC PUBLISHING (UK) LIMITED\n",
    "            Normalized Text: JERRY CHESNUT/Mike Hoyer\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=100,  # Limit the output tokens\n",
    "        temperature=0,  # Make the output deterministic\n",
    "        stop=[\"\\n\"]  # Stop generation after the normalized text\n",
    "    )\n",
    "\n",
    "    # Extract the generated text\n",
    "    normalized_text = response.choices[0].message.content.strip()\n",
    "    return normalized_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f58cb68-2dc5-412e-934b-6568bf6212a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "raw_texts = [\n",
    "    \"Jordan Riley/Adam Argyle/Copyright Control\",\n",
    "    \"Budde Music/Lorenz Brunner\",\n",
    "    \"Tony Grace/Rob DeBoer\"\n",
    "]\n",
    "\n",
    "# Normalize each raw text\n",
    "for raw_text in raw_texts:\n",
    "    normalized_text = normalize_with_gpt(raw_text, prompt)\n",
    "    print(f\"Raw Text: {raw_text}\")\n",
    "    print(f\"Normalized Text: {normalized_text}\")\n",
    "    print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "GPT-4o",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
